
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Loss and Cost Functions &#8212; Introduction&lt;br&gt; to Machine Learning</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" href="../_static/styles/sphinx-book-theme.css?digest=5115cc725059bd94278eecd172e13a965bf8f5a9" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/proof.css" />
    <link rel="stylesheet" type="text/css" href="../_static/design-style.b7bb847fb20b106c3d81b95245e65545.min.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?digest=9c920249402e914e316237a7dbc6769907cce411"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Training Neural Networks" href="training_0_intro.html" />
    <link rel="prev" title="Activation Functions" href="model_rep_2_activation_functions.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../_static/logo.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Introduction<br> to Machine Learning</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../intro.html">
                    Introduction to Machine Learning
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  About this course
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../about/teaching_philosophy.html">
   Teaching philosophy
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../about/instructor.html">
   Instructor &amp; Credits
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../about/schedule.html">
   Schedule
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../about/tools.html">
   Tools
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../about/evaluation.html">
   Evaluation
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  The basics
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../basics/linear_regression.html">
   Warm-up: Linear Regression
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../basics/lin_reg_1_notations.html">
     Notations
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../basics/lin_reg_2_cost_function.html">
     Cost Function in Linear Regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../basics/lin_reg_3_gradient_descent_1d.html">
     Gradient Descent in 1D
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../basics/lin_reg_4_gradient_descent_multiD.html">
     Multivariate Linear Regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../basics/lin_reg_5_learning_rate.html">
     Learning Rate
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../basics/lin_reg_6_gradient_descent_in_practice.html">
     Gradient Descent in Practice
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../basics/logistic_regression.html">
   Logistic Regression
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../basics/log_reg_1_intro.html">
     Logistic Regression: introduction
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../basics/log_reg_2_sigmoid.html">
     What is the Sigmoid Function?
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../basics/log_reg_3_cost_function.html">
     Cost Function for Classification
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../basics/log_reg_4_gradient_descent.html">
     Gradient Descent for Logistic Regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../basics/log_reg_5_multiclass.html">
     Multiclass Classification
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../basics/model_evaluation.html">
   Model Evaluation
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
  <label for="toctree-checkbox-3">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../basics/model_eval_1_train_test_split.html">
     Splitting Datasets for Evaluation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../basics/model_eval_2_perf_metrics.html">
     Performance Metrics
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../basics/model_eval_3_roc_curve.html">
     Let’s ROC!
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../basics/model_eval_4_bias_variance_tradeoff.html">
     Bias &amp; Variance: a Tradeoff
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Decision trees and boosting
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../trees/dt_0_and_boosting.html">
   Decision Trees
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
  <label for="toctree-checkbox-4">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../trees/dt_1_what_are_trees.html">
     What are Decision Trees?
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../trees/dt_2_cart_algorithm.html">
     The CART Algorithm
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../trees/dt_3_limitations.html">
     Limitations
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../trees/el_0_intro.html">
   Ensemble Learning
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
  <label for="toctree-checkbox-5">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../trees/el_1_what_is_ensemble.html">
     What is Ensemble Learning?
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../trees/el_2_random_forests.html">
     Random Forests
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../trees/boost_0_intro.html">
   Boosting
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/>
  <label for="toctree-checkbox-6">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../trees/boost_1_what_is_boosting.html">
     What is Boosting?
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../trees/boost_2_adaboost.html">
     AdaBoost
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../trees/boost_3_gradient_boosting.html">
     Gradient Boosting
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Neural Networks
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="nn_0_intro.html">
   Introduction
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="nn_1_motivations.html">
   Motivations
  </a>
 </li>
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="model_rep.html">
   Essential Concepts
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/>
  <label for="toctree-checkbox-7">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2">
    <a class="reference internal" href="model_rep_1_neurons.html">
     The basic units: neurons
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="model_rep_2_activation_functions.html">
     Activation Functions
    </a>
   </li>
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     Loss and Cost Functions
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="training_0_intro.html">
   Training Neural Networks
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/>
  <label for="toctree-checkbox-8">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="training_1_forward_prop.html">
     Feedforward Propagation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="training_2_backprop.html">
     Backpropagation Algorithm
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="training_3_init.html">
     Initialization Schemes
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="optim_0_intro.html">
   Optimizing Neural Networks
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/>
  <label for="toctree-checkbox-9">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="optim_1_sdg.html">
     Stochastic Gradient Descent
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="optim_2_hyperparams.html">
     Hyperparameter Search
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="optim_3_lr_scheduling.html">
     Learning Rate Schedulers
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="optim_4_adaptive_methods.html">
     Adaptive Optimizers
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="train_your_nn.html">
   Train Your Neural Net!
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Unsupervised Learning
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../unsupervised/ul_0_intro.html">
   Learning Without Labels?
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../unsupervised/ul_1_kmeans.html">
   Clustering: k-Means
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../unsupervised/ul_2_pca.html">
   Principal Component Analysis (PCA)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../unsupervised/ul_3_autoencoders.html">
   Autoencoders
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  STEP UP!
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../studies/studies_what_is_it.html">
   What is STEP?
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/>
  <label for="toctree-checkbox-10">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../studies/studies_list.html">
     List of STEPs
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../studies/studies_submit_yours.html">
     Submit Your Own STEP!
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  AI Ethics &amp; Outlook
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../ethics_outlook/ethics_0_intro.html">
   AI Ethics: What is it?
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" type="checkbox"/>
  <label for="toctree-checkbox-11">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../ethics_outlook/ethics_1_definitions.html">
     Definitions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ethics_outlook/ethics_2_why_matters.html">
     Why Does It Matter?
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ethics_outlook/ethics_3_resources.html">
     Resources
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../ethics_outlook/outlook.html">
   Outlook
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Tutorial area
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../tutorials/t00_setup.html">
   Setup
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../tutorials/t01_linear_regressor.html">
   T1. Linear Regressor
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../tutorials/t02_classifier.html">
   T2. Classifier
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../tutorials/t03_decision_stump.html">
   T3. Decision Stump
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../tutorials/t04_forestry.html">
   T4. Forestry
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../tutorials/t05_nn_by_hand.html">
   T5. Neural Network by Hand!
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../tutorials/t06_unsupervised.html">
   T6. Unsupervised algorithms
  </a>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="../_sources/nn/model_rep_3_loss_cost.md"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.md</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#terminology-general-definitions">
   Terminology - General definitions
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#loss-functions-for-regression">
   Loss Functions for Regression
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#mean-squared-error-mse">
     Mean Squared Error (MSE)
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#absolute-loss">
     Absolute Loss
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#huber-loss">
     Huber Loss
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#loss-functions-for-classification">
   Loss Functions for Classification
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#binary-cross-entropy">
     Binary Cross-Entropy
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#categorical-cross-entropy">
     Categorical Cross-Entropy
    </a>
   </li>
  </ul>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Loss and Cost Functions</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#terminology-general-definitions">
   Terminology - General definitions
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#loss-functions-for-regression">
   Loss Functions for Regression
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#mean-squared-error-mse">
     Mean Squared Error (MSE)
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#absolute-loss">
     Absolute Loss
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#huber-loss">
     Huber Loss
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#loss-functions-for-classification">
   Loss Functions for Classification
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#binary-cross-entropy">
     Binary Cross-Entropy
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#categorical-cross-entropy">
     Categorical Cross-Entropy
    </a>
   </li>
  </ul>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <section class="tex2jax_ignore mathjax_ignore" id="loss-and-cost-functions">
<h1>Loss and Cost Functions<a class="headerlink" href="#loss-and-cost-functions" title="Permalink to this headline">#</a></h1>
<p>A quick refresher of what we saw in the first lectures… with a few small tweaks in notation to fit the neural network world.</p>
<section id="terminology-general-definitions">
<h2>Terminology - General definitions<a class="headerlink" href="#terminology-general-definitions" title="Permalink to this headline">#</a></h2>
<p>One should not confuse cost and loss.</p>
<div class="proof definition admonition" id="costnndef">
<p class="admonition-title"><span class="caption-number">Definition 60 </span></p>
<section class="definition-content" id="proof-content">
<p>The <strong>loss function</strong> quantifies the difference between the actual and predicted value for one sample instance.</p>
<p>The <strong>cost function</strong> aggregates the differences of all instances of the dataset. It can have a regularization term.</p>
</section>
</div><div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>The loss function is not to be confused with the hypothesis function <span class="math notranslate nohighlight">\(h_{W,b}(x^{(i)})\)</span> that serves to build a prediction <span class="math notranslate nohighlight">\(\hat{y}^{(i)}\)</span> for sample <span class="math notranslate nohighlight">\(i\)</span>.</p>
<p>This is not to be confused with the activation function either, which only gets the information from the artificial neuron’s inputs (data or neurons’ output values), and does not perform any comparison with the observed values <span class="math notranslate nohighlight">\(\boldsymbol{y}\)</span>.</p>
</div>
</section>
<section id="loss-functions-for-regression">
<h2>Loss Functions for Regression<a class="headerlink" href="#loss-functions-for-regression" title="Permalink to this headline">#</a></h2>
<section id="mean-squared-error-mse">
<h3>Mean Squared Error (MSE)<a class="headerlink" href="#mean-squared-error-mse" title="Permalink to this headline">#</a></h3>
<p>The most commonly used loss function is the Mean Squared Error (MSE) that we are now familiar with. If we have only one output node:</p>
<div class="math notranslate nohighlight" id="equation-lossmseeq">
<span class="eqno">(77)<a class="headerlink" href="#equation-lossmseeq" title="Permalink to this equation">#</a></span>\[L \left(\;\hat{y}^{(i)}, y^{(i)}\;\right)=  \left(  \hat{y}^{(i)} - y^{(i)}  \right)^2\]</div>
<p>where <span class="math notranslate nohighlight">\(i\)</span> here is the sample number.</p>
<p>For several output dimensions (e.g. multiple regression targets or classes), we sum the squared differences across all components:</p>
<div class="math notranslate nohighlight" id="equation-lossmsekeq">
<span class="eqno">(78)<a class="headerlink" href="#equation-lossmsekeq" title="Permalink to this equation">#</a></span>\[L \left(\;\boldsymbol{\hat{y}}^{(i)}, \boldsymbol{y}^{(i)}\;\right)= \;\sum_{k = 1}^K  \left( \hat{y}^{(i)}_k - y^{(i)}_k \right)^2\]</div>
<p>with the <span class="math notranslate nohighlight">\(k\)</span> indices being the prediction or observed value for the node <span class="math notranslate nohighlight">\(k\)</span>.</p>
<p>Then the cost function would be the average of the losses over all the training sample of <span class="math notranslate nohighlight">\(m\)</span> instances:</p>
<div class="math notranslate nohighlight" id="equation-costmsekeq">
<span class="eqno">(79)<a class="headerlink" href="#equation-costmsekeq" title="Permalink to this equation">#</a></span>\[C \left(\;\boldsymbol{\hat{y}}, \boldsymbol{y}\;\right)= \frac{1}{m} \sum_{i=1}^m \sum_{k = 1}^K  \left( \hat{y}^{(i)}_k - y^{(i)}_k \right)^2\]</div>
</section>
<section id="absolute-loss">
<h3>Absolute Loss<a class="headerlink" href="#absolute-loss" title="Permalink to this headline">#</a></h3>
<p>If there are lots of outliers in the training set, aka samples associated with a large error between the prediction and the observed values, the Mean Squared Errror will make the loss (and cost) very big. A preferable choice would be to take the absolute loss:</p>
<div class="math notranslate nohighlight" id="equation-lossabseq">
<span class="eqno">(80)<a class="headerlink" href="#equation-lossabseq" title="Permalink to this equation">#</a></span>\[L \left(\;\hat{y}^{(i)}_k, y^{(i)}_k\;\right)= \left| \;\hat{y}_k^{(i)} - y_k^{(i)} \; \right|\]</div>
</section>
<section id="huber-loss">
<h3>Huber Loss<a class="headerlink" href="#huber-loss" title="Permalink to this headline">#</a></h3>
<p>The Huber Loss is a compromise of the two functions above. It is quadratic when the error is smaller than a threshold <span class="math notranslate nohighlight">\(\delta\)</span> but linear when the error is larger. The linear part makes it less sensitive to outliers than with MSE. The quadratic part allows it to converge faster and be more precise than the absolute error.</p>
<div class="math notranslate nohighlight" id="equation-losshubereq">
<span class="eqno">(81)<a class="headerlink" href="#equation-losshubereq" title="Permalink to this equation">#</a></span>\[\begin{split}L_\delta \left(\;\hat{y}^{(i)}_k, y^{(i)}_k\;\right)= 
\begin{cases}
\;\; \frac{1}{2}\;\left(\;\hat{y}^{(i)}_k-y^{(i)}_k \;\right)^2 &amp; \text { for } \left|\; \hat{y}^{(i)}_k-y^{(i)}_k \right| \leq \delta \\[2ex]
\;\; \delta \cdot\left(\;\left|\;\hat{y}^{(i)}_k-y^{(i)}_k\;\right|-\frac{1}{2} \; \delta \; \right), &amp; \text { otherwise }
\end{cases}\end{split}\]</div>
</section>
</section>
<section id="loss-functions-for-classification">
<h2>Loss Functions for Classification<a class="headerlink" href="#loss-functions-for-classification" title="Permalink to this headline">#</a></h2>
<section id="binary-cross-entropy">
<h3>Binary Cross-Entropy<a class="headerlink" href="#binary-cross-entropy" title="Permalink to this headline">#</a></h3>
<p>We are familiar with this one as it was introduced in Lecture 3. We will rewrite it as a reminder:</p>
<div class="math notranslate nohighlight" id="equation-lossbinceeq">
<span class="eqno">(82)<a class="headerlink" href="#equation-lossbinceeq" title="Permalink to this equation">#</a></span>\[L \left(\;\hat{y}^{(i)}, y^{(i)}\;\right)=-\left[ \;y^{(i)}  \log \left(\hat{y}^{(i)}\right)+\left(1-y^{(i)}\right) \log \left(1-\hat{y}^{(i)}\right) \; \right]\]</div>
<p>And the cost function will be</p>
<div class="math notranslate nohighlight" id="equation-costbinceeq">
<span class="eqno">(83)<a class="headerlink" href="#equation-costbinceeq" title="Permalink to this equation">#</a></span>\[C \left(\;\hat{y}, y\;\right) = - \frac{1}{m} \sum_{i=1}^m \left[ \;y^{(i)}  \log \left(\hat{y}^{(i)}\right)+\left(1-y^{(i)}\right) \log \left(1-\hat{y}^{(i)}\right) \; \right] \]</div>
<aside class="margin sidebar">
<p class="sidebar-title"></p>
<p>Recall that <span class="math notranslate nohighlight">\(\hat{y}^{(i)} = h_{\boldsymbol{W},\boldsymbol{b}}(\boldsymbol{x}^{(i)})\)</span>.</p>
</aside>
<p>There is nothing new here, except that the predictions <span class="math notranslate nohighlight">\(\boldsymbol{\hat{y}}^{(i)}\)</span> from the hypothesis function are not a linear function but the output of the entire neural network forward propagation.</p>
</section>
<section id="categorical-cross-entropy">
<h3>Categorical Cross-Entropy<a class="headerlink" href="#categorical-cross-entropy" title="Permalink to this headline">#</a></h3>
<p>A neural network with one output node will classify from two classes: <span class="math notranslate nohighlight">\(y=1\)</span> and <span class="math notranslate nohighlight">\(y=0\)</span>. The cross-entropy is the sum of the actual outcome multiplied by the logarithm of the outcome predicted by the model. If we have more than two classes, we can write the outcome of a given training data instance <span class="math notranslate nohighlight">\(i\)</span> as a vector:</p>
<div class="math notranslate nohighlight" id="equation-catvecobseq">
<span class="eqno">(84)<a class="headerlink" href="#equation-catvecobseq" title="Permalink to this equation">#</a></span>\[\boldsymbol{y}^{(i)} = ( 1, 0, 0, \cdots 0)\]</div>
<p>of K elements, where K is the number of output nodes. A sample belonging to the class <span class="math notranslate nohighlight">\(k\)</span> corresponds to the row index <span class="math notranslate nohighlight">\(k\)</span>. For instance a sample of the second class (the order is to be defined by convention) would be <span class="math notranslate nohighlight">\(\boldsymbol{y}^{(i)} = (0, 1, 0, \cdots 0 )\)</span>.</p>
<p>A multi-class neural network would produce vectorial predictions for one sample of the form:</p>
<div class="math notranslate nohighlight" id="equation-ypredmulticlasseq">
<span class="eqno">(85)<a class="headerlink" href="#equation-ypredmulticlasseq" title="Permalink to this equation">#</a></span>\[\boldsymbol{\hat{y}}^{(i)} = (0.15, 0.68, \cdots , 0.03)\]</div>
<aside class="margin sidebar">
<p class="sidebar-title"></p>
<p>The categorical cross-entropy is appropriate in combination with an activation function such as the softmax that can produce several probabilities for the number of classes that sum up to 1.</p>
</aside>
<p>Mutually exclusive classes would mean that for each <span class="math notranslate nohighlight">\(\boldsymbol{\hat{y}}^{(i)} = (\hat{y}^{(i)}_1, \hat{y}^{(i)}_2, \cdots, \hat{y}^{(i)}_K)\)</span>, all output values should add up to 1:</p>
<div class="math notranslate nohighlight" id="equation-ymulticlassoneeq">
<span class="eqno">(86)<a class="headerlink" href="#equation-ymulticlassoneeq" title="Permalink to this equation">#</a></span>\[\sum_{k=1}^K \; \hat{y}^{(i)}_k = 1\]</div>
<aside class="margin sidebar">
<p class="sidebar-title"></p>
<p>This is the general equation for <span class="math notranslate nohighlight">\(K\)</span> classes.</p>
</aside>
<p>The categorial cross-entropy reduces to the binary equation <a class="reference internal" href="#equation-lossbinceeq">(82)</a> for <span class="math notranslate nohighlight">\(K =2\)</span>.</p>
<div class="math notranslate nohighlight" id="equation-losscateq">
<span class="eqno">(87)<a class="headerlink" href="#equation-losscateq" title="Permalink to this equation">#</a></span>\[L \left(\;\hat{y}^{(i)}_k, y^{(i)}_k\;\right)=  - \sum_{k=1}^K \; y^{(i)}_k \log \left( \hat{y}_k^{(i)} \right) \]</div>
<p>And the cost function becomes:</p>
<div class="math notranslate nohighlight" id="equation-costcateq">
<span class="eqno">(88)<a class="headerlink" href="#equation-costcateq" title="Permalink to this equation">#</a></span>\[C \left(\;\boldsymbol{\hat{y}}, \boldsymbol{y}\;\right) = - \frac{1}{m} \sum_{i=1}^m \sum_{k=1}^K \; y^{(i)}_k \log \left( \hat{y}^{(i)}_k \right) \]</div>
<p>We’re done with the anatomy of our little neurons. Now let’s see how to train them!</p>
</section>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./nn"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="model_rep_2_activation_functions.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">Activation Functions</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="training_0_intro.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Training Neural Networks</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    <div class="extra_footer">
      <div style="display:flex; align-items:center; gap:10px;">
  <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/">
    <img src="https://licensebuttons.net/l/by-nc-sa/3.0/88x31.png" alt="CC Logo">
  </a>
  <div>
    By Claire David • © 2025<br>
    <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a>
  </div>
</div>

    </div>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>