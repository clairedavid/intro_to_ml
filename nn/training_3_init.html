
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Initialization Schemes &#8212; Introduction&lt;br&gt; to Machine Learning</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" href="../_static/styles/sphinx-book-theme.css?digest=5115cc725059bd94278eecd172e13a965bf8f5a9" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/proof.css" />
    <link rel="stylesheet" type="text/css" href="../_static/design-style.b7bb847fb20b106c3d81b95245e65545.min.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?digest=9c920249402e914e316237a7dbc6769907cce411"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Optimizing Neural Networks" href="optim_0_intro.html" />
    <link rel="prev" title="Backpropagation Algorithm" href="training_2_backprop.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../_static/logo.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Introduction<br> to Machine Learning</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../intro.html">
                    Introduction to Machine Learning
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  About this course
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../about/teaching_philosophy.html">
   Teaching philosophy
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../about/instructor.html">
   Instructor &amp; Credits
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../about/schedule.html">
   Schedule
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../about/tools.html">
   Tools
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../about/evaluation.html">
   Evaluation
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  The basics
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../basics/linear_regression.html">
   Warm-up: Linear Regression
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../basics/lin_reg_1_notations.html">
     Notations
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../basics/lin_reg_2_cost_function.html">
     Cost Function in Linear Regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../basics/lin_reg_3_gradient_descent_1d.html">
     Gradient Descent in 1D
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../basics/lin_reg_4_gradient_descent_multiD.html">
     Multivariate Linear Regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../basics/lin_reg_5_learning_rate.html">
     Learning Rate
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../basics/lin_reg_6_gradient_descent_in_practice.html">
     Gradient Descent in Practice
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../basics/logistic_regression.html">
   Logistic Regression
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../basics/log_reg_1_intro.html">
     Logistic Regression: introduction
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../basics/log_reg_2_sigmoid.html">
     What is the Sigmoid Function?
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../basics/log_reg_3_cost_function.html">
     Cost Function for Classification
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../basics/log_reg_4_gradient_descent.html">
     Gradient Descent for Logistic Regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../basics/log_reg_5_multiclass.html">
     Multiclass Classification
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../basics/model_evaluation.html">
   Model Evaluation
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
  <label for="toctree-checkbox-3">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../basics/model_eval_1_train_test_split.html">
     Splitting Datasets for Evaluation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../basics/model_eval_2_perf_metrics.html">
     Performance Metrics
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../basics/model_eval_3_roc_curve.html">
     Let’s ROC!
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../basics/model_eval_4_bias_variance_tradeoff.html">
     Bias &amp; Variance: a Tradeoff
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Decision trees and boosting
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../trees/dt_0_and_boosting.html">
   Decision Trees
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
  <label for="toctree-checkbox-4">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../trees/dt_1_what_are_trees.html">
     What are Decision Trees?
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../trees/dt_2_cart_algorithm.html">
     The CART Algorithm
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../trees/dt_3_limitations.html">
     Limitations
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../trees/el_0_intro.html">
   Ensemble Learning
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
  <label for="toctree-checkbox-5">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../trees/el_1_what_is_ensemble.html">
     What is Ensemble Learning?
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../trees/el_2_random_forests.html">
     Random Forests
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../trees/boost_0_intro.html">
   Boosting
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/>
  <label for="toctree-checkbox-6">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../trees/boost_1_what_is_boosting.html">
     What is Boosting?
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../trees/boost_2_adaboost.html">
     AdaBoost
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../trees/boost_3_gradient_boosting.html">
     Gradient Boosting
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Neural Networks
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="nn_0_intro.html">
   Introduction
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="nn_1_motivations.html">
   Motivations
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="model_rep.html">
   Essential Concepts
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/>
  <label for="toctree-checkbox-7">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="model_rep_1_neurons.html">
     The basic units: neurons
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="model_rep_2_activation_functions.html">
     Activation Functions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="model_rep_3_loss_cost.html">
     Loss and Cost Functions
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="training_0_intro.html">
   Training Neural Networks
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/>
  <label for="toctree-checkbox-8">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2">
    <a class="reference internal" href="training_1_forward_prop.html">
     Feedforward Propagation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="training_2_backprop.html">
     Backpropagation Algorithm
    </a>
   </li>
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     Initialization Schemes
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="optim_0_intro.html">
   Optimizing Neural Networks
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/>
  <label for="toctree-checkbox-9">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="optim_1_sdg.html">
     Stochastic Gradient Descent
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="optim_2_hyperparams.html">
     Hyperparameter Search
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="optim_3_lr_scheduling.html">
     Learning Rate Schedulers
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="optim_4_adaptive_methods.html">
     Adaptive Optimizers
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="train_your_nn.html">
   Train Your Neural Net!
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Unsupervised Learning
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../unsupervised/ul_0_intro.html">
   Learning Without Labels?
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../unsupervised/ul_1_kmeans.html">
   Clustering: k-Means
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../unsupervised/ul_2_pca.html">
   Principal Component Analysis (PCA)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../unsupervised/ul_3_autoencoders.html">
   Autoencoders
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  STEP UP!
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../studies/studies_what_is_it.html">
   What is STEP?
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/>
  <label for="toctree-checkbox-10">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../studies/studies_list.html">
     List of STEPs
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../studies/studies_submit_yours.html">
     Submit Your Own STEP!
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  AI Ethics &amp; Outlook
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../ethics_outlook/ethics_0_intro.html">
   AI Ethics: What is it?
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" type="checkbox"/>
  <label for="toctree-checkbox-11">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../ethics_outlook/ethics_1_definitions.html">
     Definitions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ethics_outlook/ethics_2_why_matters.html">
     Why Does It Matter?
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ethics_outlook/ethics_3_resources.html">
     Resources
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../ethics_outlook/outlook.html">
   Outlook
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Tutorial area
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../tutorials/t00_setup.html">
   Setup
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../tutorials/t01_linear_regressor.html">
   T1. Linear Regressor
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../tutorials/t02_classifier.html">
   T2. Classifier
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../tutorials/t03_decision_stump.html">
   T3. Decision Stump
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../tutorials/t04_forestry.html">
   T4. Forestry
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../tutorials/t05_nn_by_hand.html">
   T5. Neural Network by Hand!
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../tutorials/t06_unsupervised.html">
   T6. Unsupervised algorithms
  </a>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="../_sources/nn/training_3_init.md"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.md</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#introduction">
   Introduction
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#everyone-at-zero">
     Everyone at zero?
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#don-t-die-don-t-explode-don-t-saturate">
     Don’t die, don’t explode, don’t saturate
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#standard-initialization-strategies">
   Standard Initialization Strategies
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#xavier-weight-initialization">
     Xavier Weight Initialization
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#lecun-weight-initialization">
     LeCun Weight Initialization
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#he-weight-initialization">
     He Weight Initialization
    </a>
   </li>
  </ul>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Initialization Schemes</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#introduction">
   Introduction
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#everyone-at-zero">
     Everyone at zero?
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#don-t-die-don-t-explode-don-t-saturate">
     Don’t die, don’t explode, don’t saturate
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#standard-initialization-strategies">
   Standard Initialization Strategies
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#xavier-weight-initialization">
     Xavier Weight Initialization
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#lecun-weight-initialization">
     LeCun Weight Initialization
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#he-weight-initialization">
     He Weight Initialization
    </a>
   </li>
  </ul>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <section class="tex2jax_ignore mathjax_ignore" id="initialization-schemes">
<h1>Initialization Schemes<a class="headerlink" href="#initialization-schemes" title="Permalink to this headline">#</a></h1>
<br>
<br>
<br>
<p>Let’s start this section with the main question it will answer.</p>
<p>Refrain from scrolling down too much as it contains spoilers!</p>
<p>Think of it first!</p>
<br>
<br>
<br>
<div class="seealso admonition">
<p class="admonition-title">Exercise</p>
<p>How should the weights be initialized for a neural network to work?</p>
<p>Give it a try yourself and share your findings in groups of 3 or 4.</p>
</div>
<br>
<div class="tip dropdown admonition">
<p class="admonition-title">Expand if you need tips and hints</p>
<p>Ask yourself:</p>
<ul class="simple">
<li><p>Should all weights be initialized or not?</p></li>
<li><p>Would some values pose problem?</p></li>
<li><p>Recall how we did for linear and logistic regression. Could we proceed the same here?</p></li>
</ul>
</div>
<br>
<br>
<br>
<br>
<p>Initialization is a crucial processs for neural networks. The initial values can determine if the training will succeed or not, i.e. if the fit to the data will converge or not.</p>
<section id="introduction">
<h2>Introduction<a class="headerlink" href="#introduction" title="Permalink to this headline">#</a></h2>
<section id="everyone-at-zero">
<h3>Everyone at zero?<a class="headerlink" href="#everyone-at-zero" title="Permalink to this headline">#</a></h3>
<p>We could ask ourself: should we simply put all weights to zero?<br />
This corresponds to deactivating all neurons. The formula <span class="math notranslate nohighlight">\(\boldsymbol{a}^{(i, \: \ell)} = f\left[ \; \left(W^{(\ell)}\right)^\top \; \boldsymbol{a}^{(i, \: \ell -1)} \;+\; \boldsymbol{b}^{(\ell)} \;\right]\)</span> would make no progress through all layers if all weights and biases are zero.</p>
<p>We will see after covering backpropagation in the next section that any other constant for the weight initialization will lead to a problem.</p>
</section>
<section id="don-t-die-don-t-explode-don-t-saturate">
<h3>Don’t die, don’t explode, don’t saturate<a class="headerlink" href="#don-t-die-don-t-explode-don-t-saturate" title="Permalink to this headline">#</a></h3>
<p>These should be the rules for weight initialization. Explanations.</p>
<p>If we use a different number than zero, then we will validate the “don’t die” part. But which values to choose?</p>
<aside class="margin sidebar">
<p class="sidebar-title"></p>
<p><a class="reference external" href="https://proceedings.mlr.press/v9/glorot10a/glorot10a.pdf">Xavier Glorot, Yoshua Bengio, <em>Understanding the difficulty of training deep feedforward neural networks</em> (2010)</a></p>
</aside>
<p>The non-zero values should not lead to saturation nor explosion of the gradients. This must remind you of something. Yes: those were issues posed by some activation functions when their input values become large (Section <a class="reference internal" href="model_rep_2_activation_functions.html#nn1-activationf-risksgradient"><span class="std std-ref">The risk of vanishing or exploding gradients</span></a>). But it has been found that the initialization could also make a neural network unstable. The whole instability problem of neural network was not clear until a paper (link on the right) in 2010 from Xavier Glorot and Yoshua Bengio revealed the culprits.</p>
<p>At that time, there were heuristics found before 2010 (you will see why soon) consisting of initializing all weights to random values between -1 to 1, or -0.3 to 0.3 or either asymmetrically from 0 to 1. The weight values would follow either a Gaussian or uniform distribution. These heuristics work well in general. But the paper authors showed that the combination of a sigmoid as activation function with such initialization methods produces outputs with a larger variance than the inputs at the previous layer. The phenomenon amplifies itself layer after layer, eventually leading to saturation at the last layer. And as the sigmoid is not centered on zero but 0.5, this actually makes it even worse.</p>
<p>Luckily the same authors in the same paper suggested a way to mitigate this, and with other experts (and papers) they proposed ‘modern’ initialization methods that we will present in the next section.</p>
</section>
</section>
<section id="standard-initialization-strategies">
<h2>Standard Initialization Strategies<a class="headerlink" href="#standard-initialization-strategies" title="Permalink to this headline">#</a></h2>
<p>Let’s first define the notion of <em>fan-in</em> and <em>fan-out</em>.</p>
<div class="proof definition admonition" id="fanindef">
<p class="admonition-title"><span class="caption-number">Definition 64 </span></p>
<section class="definition-content" id="proof-content">
<p>In a neural network, <strong>fan-in</strong> refers to the number of incoming network connections<br />
(input neurons and bias of the previous layer)</p>
<p>The <strong>fan-out</strong> is the number of outgoing connections, i.e. the number of neurons of the layer.</p>
</section>
</div><section id="xavier-weight-initialization">
<span id="nn2-init-xavier"></span><h3>Xavier Weight Initialization<a class="headerlink" href="#xavier-weight-initialization" title="Permalink to this headline">#</a></h3>
<p>In their 2010 paper, the authors Glorot and Bengio showed that the signal needs to flow properly while making predictions (forward propagation) as well as in the reverse direction while backpropaging the gradients. What is meant by ‘flowing properly is to have a constraint on the variance:</p>
<div class="proof property admonition" id="varianceinitxavier">
<p class="admonition-title"><span class="caption-number">Property 1 </span></p>
<section class="property-content" id="proof-content">
<p>The variance of the outputs at each layer should be equal to the variance of its inputs.</p>
</section>
</div><div class="proof property admonition" id="gradientsinitxavier">
<p class="admonition-title"><span class="caption-number">Property 2 </span></p>
<section class="property-content" id="proof-content">
<p>The gradients should have equal variance before and after flowing through a layer in the reverse direction.</p>
</section>
</div><p>It is impossible to validate the two properties at the same time. But Glorot and Bengio offered a compromise that passed the experimental tests with success, mostly with the sigmoid activation function.</p>
<div class="proof definition admonition" id="xavieruniformdef">
<p class="admonition-title"><span class="caption-number">Definition 65 </span></p>
<section class="definition-content" id="proof-content">
<p>The <strong>Uniform Xavier Initialization</strong> is obtained by drawing each weight from a random uniform distribution in in <span class="math notranslate nohighlight">\([-x,x]\)</span>, with</p>
<div class="math notranslate nohighlight">
\[ x= \sqrt{\frac{6}{\textit{fan}_\text{ in} + \textit{fan}_\text{ out}}}\]</div>
</section>
</div><div class="proof definition admonition" id="xaviernormaldef">
<p class="admonition-title"><span class="caption-number">Definition 66 </span></p>
<section class="definition-content" id="proof-content">
<p>The <strong>Normal Xavier Initialization</strong> is obtained by drawing each weight from a random normal distribution with mean of 0, and a standard deviation <span class="math notranslate nohighlight">\(\sigma\)</span> of:</p>
<div class="math notranslate nohighlight">
\[ \sigma = \sqrt{\frac{2}{\textit{fan}_\text{ in} + \textit{fan}_\text{ out}}}\]</div>
</section>
</div><p>The Xavier initialization works well for sigmoid, tanh and softmax activation functions.</p>
<p>What is important here is the bounding of the variance using the numbers of inputs and outputs. It has been demonstrated that the resulting, properly scaled, distribution of the weights speeds the training considerably.</p>
</section>
<section id="lecun-weight-initialization">
<h3>LeCun Weight Initialization<a class="headerlink" href="#lecun-weight-initialization" title="Permalink to this headline">#</a></h3>
<p>A variant of Xavier initilization has been proposed by Yann LeCun, one of the godfathers of deep learning and among the top most influential AI researchers in the world. His trick is to only use the number of inputs, <em>fan-in</em>.</p>
<div class="proof definition admonition" id="lecuninitdef">
<p class="admonition-title"><span class="caption-number">Definition 67 </span></p>
<section class="definition-content" id="proof-content">
<p>The <strong>LeCun Weight Initialization</strong> is obtained by drawing each weight from a random normal distribution with mean of 0, and a standard deviation <span class="math notranslate nohighlight">\(\sigma\)</span> of:</p>
<div class="math notranslate nohighlight">
\[ \sigma = \sqrt{\frac{1}{\textit{fan}_\text{ in} }}\]</div>
</section>
</div><p>This initialization works with the SELU activation function (see Section <a class="reference internal" href="model_rep_2_activation_functions.html#nn1-activationf-selu"><span class="std std-ref">Scaled Exponential Linear Unit (SELU)</span></a>).</p>
<p> </p>
<p>Both Xavier and LeCun methods are for differentiable activation functions. The following method is for non-differentiable activation functions like ReLU.</p>
</section>
<section id="he-weight-initialization">
<h3>He Weight Initialization<a class="headerlink" href="#he-weight-initialization" title="Permalink to this headline">#</a></h3>
<p>Kaiming He and others published a paper providing a good initialization strategy for the ReLU activation function and its variants.</p>
<div class="proof definition admonition" id="heinitdef">
<p class="admonition-title"><span class="caption-number">Definition 68 </span></p>
<section class="definition-content" id="proof-content">
<p>The <strong>He Weight Initialization</strong> is obtained by drawing each weight from a random normal distribution with mean of 0, and a standard deviation <span class="math notranslate nohighlight">\(\sigma\)</span> of:</p>
<div class="math notranslate nohighlight">
\[ \sigma = \sqrt{\frac{2}{\textit{fan}_\text{ in} }}\]</div>
</section>
</div><div class="seealso admonition">
<p class="admonition-title">Learn more</p>
<ul class="simple">
<li><p>Interactive visualization of the effects of different initializations: <a class="reference external" href="https://www.deeplearning.ai/ai-notes/initialization/index.html">Initializing neural networks</a> (from www.deeplearning.ai)</p></li>
<li><p>Articles <a class="reference external" href="https://machinelearningmastery.com/weight-initialization-for-deep-learning-neural-networks/">Weight Initialization for Deep Learning Neural Networks</a> and <a class="reference external" href="https://machinelearningmastery.com/weight-initialization-for-deep-learning-neural-networks/">Why Initialize a Neural Network with Random Weights?</a> by Jason Brownlee (machinelearningmastery.com)</p></li>
<li><p><a class="reference external" href="https://365datascience.com/tutorials/machine-learning-tutorials/what-is-xavier-initialization/">What is Xavier initialization?</a> (365datascience.com)</p></li>
</ul>
</div>
</section>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./nn"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="training_2_backprop.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">Backpropagation Algorithm</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="optim_0_intro.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Optimizing Neural Networks</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    <div class="extra_footer">
      <div style="display:flex; align-items:center; gap:10px;">
  <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/">
    <img src="https://licensebuttons.net/l/by-nc-sa/3.0/88x31.png" alt="CC Logo">
  </a>
  <div>
    By Claire David • © 2025<br>
    <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a>
  </div>
</div>

    </div>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>